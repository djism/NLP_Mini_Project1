{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.1 (12 points) Implement distributional counting as described above for a provided w, V , and VC.\n",
        "Submit your code."
      ],
      "metadata": {
        "id": "OdmiRGh2-p3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# function to find indexes of words in a set within an array.\n",
        "def find_indexes(arr, words_set):\n",
        "    \"\"\"Finds all indexes of words in a set within an array using list comprehension.\"\"\"\n",
        "    return [(i, w) for i, w in enumerate(arr) if w in words_set]\n",
        "\n",
        "# function to word vectors.\n",
        "def word_vector_count(w):\n",
        "  with open(\"/vocab-15kws.txt\") as f:\n",
        "    vocab = f.read().split()\n",
        "\n",
        "  with open(\"/vocab-5k.txt\") as f1:\n",
        "    vocab_context = f1.read().split()\n",
        "\n",
        "  V = set(vocab)\n",
        "  Vc = set(vocab_context)\n",
        "\n",
        "  my_dict = defaultdict(int)\n",
        "\n",
        "  with open(\"/wiki-1percent.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        words = line.split()\n",
        "        length = len(words)\n",
        "\n",
        "        word_indexes = find_indexes(words, V)\n",
        "\n",
        "        for idx, word in word_indexes:\n",
        "            ind_l = max(0, idx - w)\n",
        "            ind_H = min(length, idx + w + 1)\n",
        "\n",
        "            context_window = words[ind_l:idx] + words[idx + 1:ind_H]\n",
        "\n",
        "            for context_word in context_window:\n",
        "                if context_word in Vc:\n",
        "                    key = (word, context_word)\n",
        "                    my_dict[key] += 1\n",
        "\n",
        "\n",
        "\n",
        "  return my_dict"
      ],
      "metadata": {
        "id": "9ZweyEbo-abg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 (6 points) Using vocab-15kws.txt to populate V and vocab-5k.txt to populate VC, use your\n",
        "code to report #(x, y) for the pairs in the following table for w = 3."
      ],
      "metadata": {
        "id": "zRE9d4vd-zi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "target_pairs = {('chicken', 'the'), ('chicken', 'wings'), ('chicago', 'chicago'), ('coffee', 'the'), ('coffee', 'cup'), ('coffee', 'coffee')}\n",
        "\n",
        "my_dict = word_vector_count(3)\n",
        "\n",
        "print(\"{:<20} {:<20}\".format('tuple', 'count'))\n",
        "\n",
        "for key, value in my_dict.items():\n",
        "    if key in target_pairs:\n",
        "        print(\"{:<20} {:<20}\".format(str(key), value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yAG09GEvOj7u",
        "outputId": "e620ef84-8681-410c-8a66-5ead6b47fde4",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuple                count               \n",
            "('coffee', 'the')    95                  \n",
            "('chicago', 'chicago') 38                  \n",
            "('chicken', 'the')   52                  \n",
            "('coffee', 'cup')    10                  \n",
            "('chicken', 'wings') 6                   \n",
            "('coffee', 'coffee') 4                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 (6 points) Using vocab-15kws.txt to populate V and vocab-5k.txt to populate VC, use your\n",
        "code to report #(x, y) for the pairs in the following table for w = 6."
      ],
      "metadata": {
        "id": "uDWbp5AsDwwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "target_pairs = {('chicken', 'the'), ('chicken', 'wings'), ('chicago', 'chicago'), ('coffee', 'the'), ('coffee', 'cup'), ('coffee', 'coffee')}\n",
        "\n",
        "my_dict = word_vector_count(6)\n",
        "\n",
        "print(\"{:<20} {:<20}\".format('tuple', 'count'))\n",
        "\n",
        "for key, value in my_dict.items():\n",
        "    if key in target_pairs:\n",
        "        print(\"{:<20} {:<20}\".format(str(key), value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6unbN6mmDD8t",
        "outputId": "525a6eee-fc37-4382-b3c5-a54b5549c8b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tuple                count               \n",
            "('coffee', 'the')    201                 \n",
            "('chicago', 'chicago') 122                 \n",
            "('chicken', 'the')   103                 \n",
            "('coffee', 'cup')    14                  \n",
            "('coffee', 'coffee') 36                  \n",
            "('chicken', 'wings') 7                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get word pairs from given datasets i.e. men.txt and simlex-999.txt."
      ],
      "metadata": {
        "id": "0vrIbtB4K057"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "# function to find pair of words and scores from given datasets.\n",
        "def make_word_pairs(path):\n",
        "  word_pairs = []\n",
        "\n",
        "  word_pair_scores = {}\n",
        "  with open(path) as f3:\n",
        "    next(f3)\n",
        "    for line in f3:\n",
        "        word1, word2, score = line.split()\n",
        "        pair = (word1, word2)\n",
        "        word_pairs.append(pair)\n",
        "        word_pair_scores[pair] = float(score)\n",
        "\n",
        "  return word_pairs, word_pair_scores"
      ],
      "metadata": {
        "id": "Cct19vt0FlG5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate cosine similarity."
      ],
      "metadata": {
        "id": "U9YJBOqJLDv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "# function to find cosine similarity.\n",
        "def cosine_similarity(vec1, vec2):\n",
        "\n",
        "    dot_product = sum(vec1[word] * vec2[word] for word in vec1 if word in vec2)\n",
        "    norm_vec1 = math.sqrt(sum(value ** 2 for value in vec1.values()))\n",
        "    norm_vec2 = math.sqrt(sum(value ** 2 for value in vec2.values()))\n",
        "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
        "        return 0.0\n",
        "    return dot_product / (norm_vec1 * norm_vec2)\n"
      ],
      "metadata": {
        "id": "rxDJOHmXFy-M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate Spearman correlation."
      ],
      "metadata": {
        "id": "CSoObB03LLXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import rankdata\n",
        "\n",
        "# function to find spearman correlation.\n",
        "def spearman_rank_correlation(predicted_similarities, actual_scores):\n",
        "\n",
        "    predicted = [predicted_similarities[pair] for pair in actual_scores if pair in predicted_similarities]\n",
        "    actual = [actual_scores[pair] for pair in actual_scores if pair in predicted_similarities]\n",
        "\n",
        "    predicted_ranks = rankdata(predicted)\n",
        "    actual_ranks = rankdata(actual)\n",
        "\n",
        "    n = len(predicted_ranks)\n",
        "    if n == 0:\n",
        "        return None\n",
        "\n",
        "    rank_differences_squared = [(pred_r - act_r) ** 2 for pred_r, act_r in zip(predicted_ranks, actual_ranks)]\n",
        "    spearman_rho = 1 - (6 * sum(rank_differences_squared)) / (n * (n**2 - 1))\n",
        "\n",
        "    return spearman_rho"
      ],
      "metadata": {
        "id": "rs1Fqr3NGJxP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 (6 points) Using w = 3 (and again using vocab-15kws.txt for V and vocab-5k.txt for VC), evaluate your count-based word vectors using EVALWS and report your results on MEN."
      ],
      "metadata": {
        "id": "ebtbsfsZLbTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "cosine_similarities_men = {}\n",
        "\n",
        "word_pairs, word_pair_scores = make_word_pairs(\"/men.txt\")\n",
        "\n",
        "word_vectors = defaultdict(dict)\n",
        "\n",
        "my_dict = word_vector_count(3)\n",
        "\n",
        "for (word, context_word), count in my_dict.items():\n",
        "    word_vectors[word][context_word] = count\n",
        "\n",
        "for (word1, word2) in word_pairs:\n",
        "    if word1 in word_vectors and word2 in word_vectors:\n",
        "\n",
        "        vec1 = word_vectors[word1]\n",
        "        vec2 = word_vectors[word2]\n",
        "\n",
        "        similarity = cosine_similarity(vec1, vec2)\n",
        "\n",
        "        cosine_similarities_men[(word1, word2)] = similarity"
      ],
      "metadata": {
        "id": "X6QzbYOqGZ2s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spearman_rho = spearman_rank_correlation(cosine_similarities_men, word_pair_scores)\n",
        "print(f\"Spearman's ρ for MEN dataset for w = 3: {spearman_rho}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fz0brZDsHjZJ",
        "outputId": "df8e594a-7e56-4b40-f131-da3aac1b89e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's ρ for MEN dataset for w = 3: 0.22536738248526467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 (6 points) Using w = 3 (and again using vocab-15kws.txt for V and vocab-5k.txt for VC), evaluate your count-based word vectors using EVALWS and report your results on simlex-999."
      ],
      "metadata": {
        "id": "ZscjHGKVLpja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "cosine_similarities_simlex999 = {}\n",
        "\n",
        "word_pairs, word_pair_scores = make_word_pairs(\"/simlex-999.txt\")\n",
        "\n",
        "for (word1, word2) in word_pairs:\n",
        "    if word1 in word_vectors and word2 in word_vectors:\n",
        "\n",
        "        vec1 = word_vectors[word1]\n",
        "        vec2 = word_vectors[word2]\n",
        "\n",
        "        similarity = cosine_similarity(vec1, vec2)\n",
        "\n",
        "        cosine_similarities_simlex999[(word1, word2)] = similarity"
      ],
      "metadata": {
        "id": "xxn2mJrjJwMH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spearman_rho = spearman_rank_correlation(cosine_similarities_simlex999, word_pair_scores)\n",
        "print(f\"Spearman's ρ for simlex-999 dataset for w = 3: {spearman_rho}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1vcLxny4Kg5s",
        "outputId": "5e7c1a83-50bd-455f-f32d-3ca0291e1d93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's ρ for simlex-999 dataset for w = 3: 0.059538612941463454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 (10 points) Extend your implementation to be able to compute IDF-based word vectors using Eq. 1. Using w = 3, vocab-15kws.txt to populate V , and vocab-5k.txt to populate VC, evaluate (EVALWS)\n",
        "your IDF-based word vectors and report your results.\n",
        "\n",
        "For men dataset"
      ],
      "metadata": {
        "id": "e94O10F4NtCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "cosine_similarities_men = {}\n",
        "\n",
        "word_pairs, word_pair_scores = make_word_pairs(\"/men.txt\")\n",
        "\n",
        "with open(\"/vocab-5k.txt\") as f1:\n",
        "    vocab_context = f1.read().split()\n",
        "\n",
        "Vc = set(vocab_context)\n",
        "\n",
        "total_lines = 0\n",
        "context_word_line_counts = defaultdict(int)\n",
        "\n",
        "with open(\"/wiki-1percent.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        total_lines += 1\n",
        "        words = set(line.split())\n",
        "\n",
        "        for word in words:\n",
        "            if word in Vc:\n",
        "                context_word_line_counts[word] += 1\n",
        "\n",
        "word_vectors = defaultdict(dict)\n",
        "\n",
        "my_dict = word_vector_count(3)\n",
        "\n",
        "for (word, context_word), count in my_dict.items():\n",
        "    count_context_word = context_word_line_counts[context_word]\n",
        "    word_vectors[word][context_word] = count*(total_lines/count_context_word)\n",
        "\n",
        "for (word1, word2) in word_pairs:\n",
        "    if word1 in word_vectors and word2 in word_vectors:\n",
        "\n",
        "        vec1 = word_vectors[word1]\n",
        "        vec2 = word_vectors[word2]\n",
        "\n",
        "        similarity = cosine_similarity(vec1, vec2)\n",
        "\n",
        "        cosine_similarities_men[(word1, word2)] = similarity"
      ],
      "metadata": {
        "id": "BrFhXK4HcifS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spearman_rho = spearman_rank_correlation(cosine_similarities_men, word_pair_scores)\n",
        "\n",
        "# Print the Spearman's ρ result\n",
        "print(f\"Spearman's ρ for MEN dataset for w = 3: {spearman_rho}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8xOMcQOJwIwA",
        "outputId": "f60e6daf-e852-48a2-9965-fd2aaf01a402"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's ρ for MEN dataset for w = 3: 0.47297401866377986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For simlex-999 dataset"
      ],
      "metadata": {
        "id": "FK7E8IPKQN3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "cosine_similarities_simlex999 = {}\n",
        "\n",
        "word_pairs, word_pair_scores = make_word_pairs(\"/simlex-999.txt\")\n",
        "\n",
        "for (word1, word2) in word_pairs:\n",
        "    if word1 in word_vectors and word2 in word_vectors:\n",
        "\n",
        "        vec1 = word_vectors[word1]\n",
        "        vec2 = word_vectors[word2]\n",
        "\n",
        "        similarity = cosine_similarity(vec1, vec2)\n",
        "\n",
        "        cosine_similarities_simlex999[(word1, word2)] = similarity"
      ],
      "metadata": {
        "id": "4ASYVqZQQfaw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spearman_rho = spearman_rank_correlation(cosine_similarities_men, word_pair_scores)\n",
        "print(f\"Spearman's ρ for simlex-999 dataset for w = 3: {spearman_rho}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pAXLq8J8Q45w",
        "outputId": "5ba2ae8e-b336-44ab-a5d0-219bc62a629f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's ρ for simlex-999 dataset for w = 3: 0.15982142857142856\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}